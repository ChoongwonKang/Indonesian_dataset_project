library(LexisNexisTools)
install.packages("LexisNexisTools")
library(LexisNexisTools)
#install.packages('tidyverse')
#library(tidyverse)
library(data.table)
library(lubridate)
install.packages('lubridate')
library(lubridate)
# ??????목록 불러??????
# LNToutput <- lnt_read(x = './docx/DOCX.DOCX')
LNToutput <- lnt_read(x = 'C:\Users\USER\Ars Praxia\[T] 23-05-001 NIA AI 데이터셋 구축 - General\06-수집데이터\기사 데이터\2023.08.03_data')
# ??????목록 불러??????
# LNToutput <- lnt_read(x = './docx/DOCX.DOCX')
LNToutput <- lnt_read(x = 'C:/Users/USER/Ars Praxia/[T] 23-05-001 NIA AI 데이터셋 구축 - General/06-수집데이터/기사 데이터/2023.08.03_data')
# 중복 기사 찾기
duplicates_df <- lnt_similarity(LNToutput = LNToutput,
threshold = 0.9,
nthread = parallel::detectCores()-1,
rel_dist = F # ???간문?????? F 처리
)
# ????????? 0.9?????? 기사 ??????
duplicates_df <- duplicates_df[duplicates_df$Similarity >= 0.9]
LNToutput <- LNToutput[!LNToutput@meta$ID %in% duplicates_df$ID_duplicate, ]
meta_articles_df <- lnt_convert(LNToutput, to = "data.frame")
meta_articles_df
# export File
fwrite(data.table(meta_articles_df),'C:/Users/USER/Ars Praxia/[T] 23-05-001 NIA AI 데이터셋 구축 - General/06-수집데이터/기사 데이터/2023.08.03_data.csv')
